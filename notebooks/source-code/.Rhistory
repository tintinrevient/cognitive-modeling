dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE))
delay <- filter(delay, count > 20, dest != "HNL")
delay
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
geom_point(mapping = aes(size = count), alpha = 1/3) +
geom_smooth(se = FALSE)
delays <- flights %>%
group_by(dest) %>%
summarise(count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)) %>%
filter(count > 20, dest != "HNL")
ggplot(data = delays, mapping = aes(x = dist, y = delay)) +
geom_point(mapping = aes(size = count), alpha = 1/3) +
geom_smooth(se = FALSE)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(delay = mean(arr_delay))
ggplot(data = delays, mapping = aes(x = delay)) +
geom_freqpoly(binwidth = 10)
delays
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(delay = mean(arr_delay), n = n())
ggplot(data = delays, mapping = aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(delay = mean(arr_delay), n = n())
delays %>%
filter(n > 25) %>%
ggplot(mapping = aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(delay = mean(arr_delay), n = n())
delays %>%
filter(n > 25) %>%
ggplot(mapping = aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(delay = mean(arr_delay), n = n())
delays %>%
filter(n > 25) %>%
ggplot(mapping = aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(avg_delay1 = mean(arr_delay),
avg_delay2 = mean(arr_delay[arr_delay > 0]))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(dest) %>%
summarise(distance_sd = sd(distance)) %>%
arrange(desc(distance_sd))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(first = min(dep_time),
last = max(dep_time))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(first = min(dep_time),
quarter1 = quantile(dep_time, 0.25),
median = median(dep_time),
quarter3 = quantile(dep_time, 0.75),
last = max(dep_time))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(first_step = first(dep_time),
last_step = last(dep_time))
range(c(1,12,3,4,))
range(c(1,12,3,4,5))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
mutate(r = min_rank(desc(dep_time))) %>%
filter(r %in% range(r))
range(c(1,12,3,4,5))
1 in range(c(1,12,3,4,5))
1 %in% range(c(1,12,3,4,5))
13 %in% range(c(1,12,3,4,5))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(dest) %>%
summarise(carriers = n_distinct(carrier)) %>%
arrange(desc(carriers))
not_cancelled %>% n_distinct(dest)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>% n_distinct(dest)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>% count(dest)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>% count(tailnum)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>% count(tailnum, wt = distance)
not_cancelled %>% count(tailnum)
not_cancelled %>% count(tailnum, wt = distance)
not_cancelled %>% count(tailnum)
not_cancelled %>%
group_by(tailnum) %>%
summarise(n = sum(distance))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(n_early = sum(dep_time < 500))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(hour_perc = mean(arr_delay > 60))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(hour_perc = sum(arr_delay > 60))
daily <- flights %>% group_by(flights, year, month, day)
daily
daily <- flights %>% group_by(flights, year, month, day)
daily
daily <- flights %>% group_by(year, month, day)
daily
(per_day <- summarise(daily, flights = n()))
(per_month <- summarise(per_day, flights = sum(flights)))
(per_year <- summarise(per_month, flights = sum(flights)))
daily
daily %>%
ungroup() %>%
summarise(flights = n())
flights_sml %>%
group_by(year, month, day) %>%
filter(rank(desc(arr_delay)) < 10)
rank(c(1,1,1,1,2,2,3,4,5))
min_rank(c(1,1,1,1,2,2,3,4,5))
popular_flights <- flights %>%
group_by(dest) %>%
filter(n() > 365)
popular_flights
jan1 <- filter(flights, month == 1, day == 1)
(jan1 <- filter(flights, month == 1, day == 1))
count(diamonds, cut)
ggplot(diamonds) + geom_histogram(mapping = aes(x = carat), binwidth = 1)
ggplot(diamonds) + geom_histogram(mapping = aes(x = carat), binwidth = 0.5)
ggplot(diamonds) + geom_histogram(mapping = aes(x = carat), binwidth = 1)
ggplot(diamonds) + geom_histogram(mapping = aes(x = carat), binwidth = 0.5)
count(diamonds, cut_width(carat, 0.5))
smaller <- diamonds %>% filter(carat < 3)
ggplot(data = smaller, mapping = aes(x = carat)) +
geom_histogram(binwidth = 0.1)
ggplot(data = smaller, mapping = aes(x = carat)) +
geom_freqpoly(binwidth = 0.1)
ggplot(data = smaller, mapping = aes(x = carat, color = cut)) +
geom_freqpoly(binwidth = 0.1)
ggplot(data = faithful, mapping = aes(x = eruptions)) +
geom_histogram(binwidth = 0.25)
View(faithful)
View(faithful)
ggplot(data = diamonds, mapping = aes(x = y)) +
geom_histogram(binwidth = 0.5)
ggplot(data = diamonds, mapping = aes(x = y)) +
geom_histogram(binwidth = 0.5) +
coord_cartesian(ylim = c(0, 50))
unusual <- diamonds %>%
filter(y < 3 | y > 20) %>%
arrange(y)
unusual
View(diamonds)
ggplot(data = diamonds, mapping = aes(x = price)) +
geom_histogram(binwidth = 10)
ggplot(data = diamonds, mapping = aes(x = price)) +
geom_histogram(binwidth = 100)
ggplot(data = diamonds, mapping = aes(x = price)) +
geom_histogram(binwidth = 300)
ggplot(data = diamonds, mapping = aes(x = price)) +
geom_histogram(binwidth = 500)
diamonds2 <- diamonds %>%
mutate(y = ifelse(y < 3 | y > 20, NA, y))
diamonds2 <- diamonds %>%
mutate(y = ifelse(y < 3 | y > 20, NA, y))
ggplot(data = diamonds2, mapping = aes(x = y)) +
geom_histogram(binwidth = 0.5) +
coord_cartesian(ylim = c(0, 50))
diamonds2 <- diamonds %>%
mutate(y = ifelse(y < 3 | y > 20, NA, y))
ggplot(data = diamonds2, mapping = aes(x = x, y = y)) +
geom_point()
diamonds2 <- diamonds %>%
mutate(y = ifelse(y < 3 | y > 20, NA, y))
ggplot(data = diamonds2, mapping = aes(x = x, y = y)) +
geom_point(na.rm = TRUE)
flights %>%
mutate(cancelled = is.na(dep_time),
sched_hour = sched_dep_time %/% 100,
sched_min = sched_dep_time %% 100,
sched_dep_time = sched_hour + sched_min / 60) %>%
ggplot(mapping = aes(x = sched_dep_time)) +
geom_freqpoly(mapping = aes(color = cancelled), binwidth = 1/4)
ggplot(data = diamonds, mapping = aes(x = price)) +
geom_freqpoly(color = cut, binwidth = 500)
ggplot(data = diamonds, mapping = aes(x = price)) +
geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) +
geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
geom_point()
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
geom_point()
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
geom_boxplot()
ggplot(data = mpg, mapping = ase(x = class, y = hwy)) +
geom_point()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_point()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot()
ggplot(data = mpg) +
geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median),
y = hwy))
ggplot(data = mpg) +
geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = mean),
y = hwy))
ggplot(data = mpg) +
geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median),
y = hwy))
ggplot(data = mpg) +
geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median),
y = hwy)) +
coord_flip()
install.packages("lvplot")
library(lvplot)
ggplot(data = diamonds) +
geom_lvplot(mapping = aes(x = cut, y = price))
library(lvplot)
ggplot(data = diamonds) +
geom_lv(mapping = aes(x = cut, y = price))
ggplot(data = diamonds) +
geom_boxplot(mapping = aes(x = cut, y = price))
ggplot(data = diamonds) +
geom_lv(mapping = aes(x = cut, y = price))
ggplot(data = diamonds) +
geom_histogram(mapping = aes(x = cut))
ggplot(data = diamonds) +
geom_histogram(mapping = aes(x = price))
ggplot(data = diamonds) +
geom_histogram(mapping = aes(x = price), binwidth = 500)
ggplot(data = diamonds) +
geom_histogram(mapping = aes(x = price), binwidth = 500) +
facet_wrap(~ cut)
?geom_violin
ggplot(data = diamonds) +
geom_violin(mapping = aes(x = price), binwidth = 500)
ggplot(data = diamonds) +
geom_violin(mapping = aes(x = price, y = ..density..))
ggplot(data = diamonds) +
geom_violin(mapping = aes(x = price, y = cut))
ggplot(data = diamonds) +
geom_count(mapping = aes(x = cut, y = color))
count(diamonds, color, cut)
diamonds %>% count(color, cut) %>%
ggplot(mapping = aes(x = color, y = cut)) +
geom_tile(mapping = aes(fill = n))
ggplot(data = diamonds) +
geom_point(mapping = aes(x = carat, y = price))
ggplot(data = diamonds) +
geom_point(mapping = aes(x = carat, y = price), alpha = 1/100)
install.packages("hexbin")
install.packages("hexbin")
smaller <- diamonds %>% filter(carat < 3)
ggplot(data = smaller) +
geom_bin2d(mapping = aes(x = carat, y = price))
ggplot(data = smaller) +
geom_jitter(mapping = aes(x = carat, y = price))
ggplot(data = smaller) +
geom_bin2d(mapping = aes(x = carat, y = price))
ggplot(data = smaller) +
geom_hex(mapping = aes(x = carat, y = price))
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)), varwidth = TRUE)
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
geom_boxplot(mapping = ase(group = cut_number(carat, 20)))
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
geom_boxplot(mapping = aes(group = cut_number(carat, 20)))
ggplot(data = smaller) +
geom_hex(mapping = aes(x = carat, y = price))
?lm
exp(2)
exp(1)
exp(3)
library(modelr)
mod <- lm(log(price) ~ log(carat), data = diamonds)
diamonds2 <- diamonds %>%
add_residuals(mod) %>%
mutate(resid = exp(resid))
ggplot(data = diamonds2) +
geom_point(mapping = aes(x = carat, y = resid))
ggplot(data = diamonds2) +
geom_boxplot(mapping = aes(x = cut, y = resid))
diamonds2 <- diamonds %>%
add_residuals(mod)
View(diamonds2)
mod <- lm(log(price) ~ log(carat), data = diamonds)
diamonds2 <- diamonds %>%
add_residuals(mod) %>%
mutate(resid = exp(resid))
View(diamonds2)
ggplot(data = diamonds2) +
geom_point(mapping = aes(x = carat, y = resid))
ggplot(data = diamonds2) +
geom_boxplot(mapping = aes(x = cut, y = resid))
library(modelr)
mod <- lm(log(price) ~ log(carat), data = diamonds)
diamonds2 <- diamonds %>%
add_residuals(mod) %>%
mutate(resid = exp(resid))
ggplot(data = diamonds2) +
geom_point(mapping = aes(x = carat, y = resid))
ggplot(data = diamonds2) +
geom_boxplot(mapping = aes(x = cut, y = resid))
library(tidyverse)
library(nycflights13)
library(modelr)
mod <- lm(log(price) ~ log(carat), data = diamonds)
diamonds2 <- diamonds %>%
add_residuals(mod) %>%
mutate(resid = exp(resid))
ggplot(data = diamonds2) +
geom_point(mapping = aes(x = carat, y = resid))
ggplot(data = diamonds2) +
geom_boxplot(mapping = aes(x = cut, y = resid))
source('~/Documents/workspace/cognitive-modeling/books/discovering-statistics-using-r/chapter-4/data/eda.R')
getwd()
source('~/Documents/workspace/cognitive-modeling/books/discovering-statistics-using-r/chapter-4/data/eda.R')
getwd()
source('~/Documents/workspace/cognitive-modeling/books/discovering-statistics-using-r/chapter-4/data/eda.R')
prior <- createUniformPrior(lower=c(-1,1), upper=c(1,50), best=NULL)
library(ggplot2)
expected.success <- function(threshold, scale.points, densityf, cumulativef) {
ifelse(threshold>min(scale.points), sum(sapply(scale.points[scale.points<threshold], function(x) {densityf(x) * densityf(x)})), 0) +
sum(sapply(scale.points[scale.points>=threshold], function(x) {densityf(x) * literal.listener(x, threshold, densityf, cumulativef)}))
}
#Task 1
utility <- function(threshold, scale.points, coverage.parameter, densityf, cumulativef) {
expected.success(threshold, scale.points, densityf, cumulativef) + coverage.parameter *
sum(sapply(threshold:max(scale.points), function(x){densityf(x)}))
}
probability.threshold <- function(threshold, scale.points, lambda, coverage.parameter, densityf, cumulativef, denominator = NULL) {
if(is.null(denominator)){
denominator = sum(sapply(scale.points, function(x) {exp(lambda * utility(x, scale.points, coverage.parameter, densityf, cumulativef))}))
}
exp(lambda * utility(threshold, scale.points, coverage.parameter, densityf, cumulativef)) / denominator
}
# use.adjective <- function(degree, scale.points, lambda, coverage.parameter, densityf, cumulativef) {
#     # if(!exists("mem")){
#     #     mem <- c()
#     # }
#     # if(degree < length(mem)){
#     #     mem <- c(0)
#     # }
#     denominator = sum(sapply(scale.points, function(x) {exp(lambda * utility(x, scale.points, coverage.parameter, densityf, cumulativef))}))
#     ptc <- probability.threshold(degree, scale.points, lambda, coverage.parameter, densityf, cumulativef, denominator)
#     print(ptc)
#     #mem <- c(mem, ptc)
#     append(mem, double(ptc))
#     print(mem)
#     sum(mem)
# }
# use.adjective <- function(degree, scale.points, lambda, coverage.parameter, densityf, cumulativef) {
#     if(!exists("mem")){
#         mem <- c()
#     }
#     # if(degree < length(mem)){
#     #     mem <- c()
#     # }
#     denominator = sum(sapply(scale.points, function(x) {exp(lambda * utility(x, scale.points, coverage.parameter, densityf, cumulativef))}))
#     mem <- c(mem, probability.threshold(degree, scale.points, lambda, coverage.parameter, densityf, cumulativef, denominator))
#     sum(mem)
# }
use.adjective <- function(degree, scale.points, lambda, coverage.parameter, densityf, cumulativef) {
denominator = sum(sapply(scale.points, function(x) {exp(lambda * utility(x, scale.points, coverage.parameter, densityf, cumulativef))}))
sum(sapply(min(scale.points):degree, function(x){probability.threshold(x, scale.points, lambda, coverage.parameter, densityf, cumulativef, denominator)}))
}
#install.packages("BayesianTools")
library(BayesianTools)
prior <- createUniformPrior(lower=c(-1,1), upper=c(1,50), best=NULL)
likelihood <- function(param1) {
collect <- 0
for (i in 1:14) {
collect  <- collect + dnorm(data.gaus.big$percentage[i], mean=use.adjective(i, c(1:14), param1[2], param1[1], densityf=function(x) {dnorm(x, 6, 2)}, cumulativef=function(x) {pnorm(x, 6, 2)}), sd=0.1, log=TRUE)
}
return(collect)
}
bayesianSetup <- createBayesianSetup(likelihood = likelihood, prior = prior)
iter = 10000
settings = list(iterations = iter, message = FALSE)
out <- runMCMC(bayesianSetup = bayesianSetup, settings = settings)
data.adjective <- read.csv(file="adjective-data.csv", header=TRUE)
getwd()
setwd("/Users/zhaoshu/Documents/workspace/cognitive-modeling/notebooks/source-code")
data.adjective <- read.csv(file="adjective-data.csv", header=TRUE)
data.gaus <- data.adjective[data.adjective$Distribution=="gaussian",]
data.left <- data.adjective[data.adjective$Distribution=="left",]
data.moved <- data.adjective[data.adjective$Distribution=="moved",]
settings = list(iterations = iter, message = FALSE)
out <- runMCMC(bayesianSetup = bayesianSetup, settings = settings)
data.gaus.big <- subset(data.gaus, Adjective == "big")
bayesianSetup <- createBayesianSetup(likelihood = likelihood, prior = prior)
iter = 10000
settings = list(iterations = iter, message = FALSE)
out <- runMCMC(bayesianSetup = bayesianSetup, settings = settings)
literal.listener <- function(x, threshold, densityf, cumulativef) {
ifelse(
x>=threshold,
densityf(x)/(1-cumulativef(threshold)),
0
)
}
out <- runMCMC(bayesianSetup = bayesianSetup, settings = settings)
summary(out)
use.adjective <- function(degree, scale.points, lambda, coverage.parameter, densityf, cumulativef, denominator) {
if(is.null(denominator))
denominator <- sum(sapply(scale.points, function(x) {exp(lambda * utility(x, scale.points, coverage.parameter, densityf, cumulativef))}))
sum(sapply(scale.points[scale.points<=degree], function(x) {probability.threshold(x, scale.points, lambda, coverage.parameter, densityf, cumulativef, denominator)}))
}
probability.threshold <- function(threshold, scale.points, lambda, coverage.parameter, densityf, cumulativef, denominator) {
if(is.null(denominator))
denominator <- sum(sapply(scale.points, function(x) {exp(lambda * utility(x, scale.points, coverage.parameter, densityf, cumulativef))}))
exp(lambda * utility(threshold, scale.points, coverage.parameter, densityf, cumulativef)) / denominator
}
# data.gaus.big
prior <- createUniformPrior(lower = c(-1, 1), upper = c(1, 50), best = NULL)
data.gaus.big <- subset(data.gaus, Adjective == "big")
# data.gaus.big
prior <- createUniformPrior(lower = c(-1, 1), upper = c(1, 50), best = NULL)
data.gaus.big <- subset(data.gaus, Adjective == "big")
scale.points <- c(1:14)
densityf <- function(x) {dnorm(x, 6, 2)}
cumulativef <- function(x) {pnorm(x, 6, 2)}
likelihood <- function(param1) {
collect <- 0
denominator <- sum(sapply(c(1:14), function(x) {exp(param1[2] * utility(x, scale.points, param1[1], densityf, cumulativef))}))
for (i in 1:14) {
collect  <- collect + dnorm(data.gaus.big$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], densityf, cumulativef, denominator), sd=0.1, log=TRUE)
}
return(collect)
}
bayesianSetup <- createBayesianSetup(likelihood = likelihood, prior = prior)
iter = 10000
settings = list(iterations = iter, message = FALSE)
out <- runMCMC(bayesianSetup = bayesianSetup, settings = settings)
summary(out)
prior <- createUniformPrior(lower = c(-1, 1), upper = c(1, 50), best = NULL)
data.gaus.big <- subset(data.gaus, Adjective == "big")
data.left.big <- subset(data.left, Adjective == "big")
data.moved.big <- subset(data.moved, Adjective == "big")
data.gaus.pointy <- subset(data.gaus, Adjective == "pointy")
data.left.pointy <- subset(data.left, Adjective == "pointy")
data.moved.pointy <- subset(data.moved, Adjective == "pointy")
data.gaus.tall <- subset(data.gaus, Adjective == "tall")
data.left.tall <- subset(data.left, Adjective == "tall")
data.moved.tall <- subset(data.moved, Adjective == "tall")
scale.points <- c(1:14)
likelihood <- function(param1) {
collect <- 0
denominator.gaus <- sum(sapply(scale.points, function(x) {exp(param1[2] * utility(x, scale.points, param1[1], function(x) {dnorm(x, 6, 2)}, function(x) {pnorm(x, 6, 2)}))}))
denominator.left <- sum(sapply(scale.points, function(x) {exp(param1[2] * utility(x, scale.points, param1[1], function(x) {dgamma(x, shape = 4, scale = 1.5)}, function(x) {pgamma(x, shape = 4, scale = 1.5)}))}))
denominator.moved <- sum(sapply(scale.points, function(x) {exp(param1[2] * utility(x, scale.points, param1[1], function(x) {dnorm(x, 9, 2)}, function(x) {pnorm(x, 9, 2)}))}))
for (i in 1:14) {
collect  <- collect +
dnorm(data.gaus.big$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dnorm(x, 6, 2)}, function(x) {pnorm(x, 6, 2)}, denominator.gaus), sd=0.1, log=TRUE) +
dnorm(data.gaus.pointy$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dnorm(x, 6, 2)}, function(x) {pnorm(x, 6, 2)}, denominator.gaus), sd=0.1, log=TRUE) +
dnorm(data.gaus.tall$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dnorm(x, 6, 2)}, function(x) {pnorm(x, 6, 2)}, denominator.gaus), sd=0.1, log=TRUE) +
dnorm(data.left.big$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dgamma(x, shape = 4, scale = 1.5)}, function(x) {pgamma(x, shape = 4, scale = 1.5)}, denominator.left), sd=0.1, log=TRUE) +
dnorm(data.left.pointy$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dgamma(x, shape = 4, scale = 1.5)}, function(x) {pgamma(x, shape = 4, scale = 1.5)}, denominator.left), sd=0.1, log=TRUE) +
dnorm(data.left.tall$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dgamma(x, shape = 4, scale = 1.5)}, function(x) {pgamma(x, shape = 4, scale = 1.5)}, denominator.left), sd=0.1, log=TRUE) +
dnorm(data.moved.big$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dnorm(x, 9, 2)}, function(x) {pnorm(x, 9, 2)}, denominator.moved), sd=0.1, log=TRUE) +
dnorm(data.moved.pointy$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dnorm(x, 9, 2)}, function(x) {pnorm(x, 9, 2)}, denominator.moved), sd=0.1, log=TRUE) +
dnorm(data.moved.tall$percentage[i], mean=use.adjective(i, scale.points, param1[2], param1[1], function(x) {dnorm(x, 9, 2)}, function(x) {pnorm(x, 9, 2)}, denominator.moved), sd=0.1, log=TRUE)
}
return(collect)
}
bayesianSetup <- createBayesianSetup(likelihood = likelihood, prior = prior)
iter = 10000
settings = list(iterations = iter, message = FALSE)
out <- runMCMC(bayesianSetup = bayesianSetup, settings = settings)
summary(out)
